{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anna-short.txt\n",
      "anna-short-Train.txt\n",
      "anna-short-SimpleNLPMapping.pkl\n",
      "anna-short-SimpleNLPModel.hdf5\n",
      "anna-short-SeedText.txt\n"
     ]
    }
   ],
   "source": [
    "sequenceLength = 10\n",
    "\n",
    "#sourceTextFileName = \"poem.txt\"\n",
    "sourceTextFileName = \"anna-short.txt\"\n",
    "trainingTextFileName = sourceTextFileName.split(\".\")[0] + \"-Train.txt\"\n",
    "mappingFileName = sourceTextFileName.split(\".\")[0] + \"-SimpleNLPMapping\" + \".pkl\"\n",
    "bestSavedModel = sourceTextFileName.split(\".\")[0] + \"-SimpleNLPModel\" + \".hdf5\"\n",
    "seedTextFileName = sourceTextFileName.split(\".\")[0] + \"-SeedText.txt\"\n",
    "\n",
    "print(sourceTextFileName)\n",
    "print(trainingTextFileName)\n",
    "print(mappingFileName)\n",
    "print(bestSavedModel)\n",
    "print(seedTextFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads and return the text of the training file. self-explanatory\n",
    "def readTextFile(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTextFile(lines, fileName):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(fileName, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRawText(rawText):\n",
    "    # split the raw text using space (' ') \n",
    "    tokens = rawText.split()\n",
    "    rawText = ' '.join(tokens)\n",
    "    \n",
    "    # basically we removed all the line/paragraph breaks\n",
    "    # but kept the punctuations\n",
    "    return rawText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequenceRawText(rawText):\n",
    "    # organize into sequences of characters\n",
    "    length = 10\n",
    "    sequences = list()\n",
    "    for i in range(length, len(rawText)):\n",
    "        # picks a sequence of tokens\n",
    "        seq = rawText[i - length:i+1]\n",
    "        # add to tlist\n",
    "        sequences.append(seq)\n",
    "        \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1\n",
      "\n",
      "\n",
      "Happy families are all alike; every unhappy family is unhappy in its own\n",
      "way.\n",
      "\n",
      "Everything was in confusion in the Oblonskys' hou\n"
     ]
    }
   ],
   "source": [
    "# load the training file\n",
    "rawText = readTextFile(sourceTextFileName)\n",
    "print(rawText[: 140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1 Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys' house.\n"
     ]
    }
   ],
   "source": [
    "rawText = processRawText(rawText)\n",
    "print(rawText[: 140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sequences: 21865\n",
      "['Chapter 1 H', 'hapter 1 Ha', 'apter 1 Hap', 'pter 1 Happ', 'ter 1 Happy']\n"
     ]
    }
   ],
   "source": [
    "# turn the text into a sequence of character\n",
    "# each sequence is sequenceLength long\n",
    "sequences = sequenceRawText(rawText)\n",
    "\n",
    "# save sequences to file\n",
    "writeTextFile(sequences, trainingTextFileName)\n",
    "\n",
    "print('Total number of sequences: %d' % len(sequences))\n",
    "print(sequences[: 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chapter 1 H', 'hapter 1 Ha', 'apter 1 Hap', 'pter 1 Happ', 'ter 1 Happy']\n"
     ]
    }
   ],
   "source": [
    "# now we read the text sequences from the file we saved\n",
    "rawTrainingText = readTextFile(trainingTextFileName)\n",
    "sequenceLines = rawTrainingText.split('\\n')\n",
    "\n",
    "print(sequenceLines[: 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 63\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '1', '2', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'W', 'Y', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '1': 10, '2': 11, '3': 12, ':': 13, ';': 14, '?': 15, 'A': 16, 'B': 17, 'C': 18, 'D': 19, 'E': 20, 'F': 21, 'G': 22, 'H': 23, 'I': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'R': 31, 'S': 32, 'T': 33, 'W': 34, 'Y': 35, '_': 36, 'a': 37, 'b': 38, 'c': 39, 'd': 40, 'e': 41, 'f': 42, 'g': 43, 'h': 44, 'i': 45, 'j': 46, 'k': 47, 'l': 48, 'm': 49, 'n': 50, 'o': 51, 'p': 52, 'q': 53, 'r': 54, 's': 55, 't': 56, 'u': 57, 'v': 58, 'w': 59, 'x': 60, 'y': 61, 'z': 62}\n"
     ]
    }
   ],
   "source": [
    "# time to encode the text\n",
    "\n",
    "# create a vocabulary (all used characters in the text)\n",
    "vocab = sorted(list(set(rawTrainingText)))\n",
    "vocabSize = len(vocab)\n",
    "\n",
    "# map each character to an integer by creating a dictionary\n",
    "vocabMap = dict((c, i) for i, c in enumerate(vocab))\n",
    "\n",
    "print(\"Vocabulary size: %d\" % vocabSize)\n",
    "print(vocab)\n",
    "print(vocabMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 44, 37, 52, 56, 41, 54, 1, 10, 1, 23], [44, 37, 52, 56, 41, 54, 1, 10, 1, 23, 37], [37, 52, 56, 41, 54, 1, 10, 1, 23, 37, 52], [52, 56, 41, 54, 1, 10, 1, 23, 37, 52, 52], [56, 41, 54, 1, 10, 1, 23, 37, 52, 52, 61]]\n"
     ]
    }
   ],
   "source": [
    "# let's turn those characters in the sequences to integers \n",
    "sequences = list()\n",
    "\n",
    "for line in sequenceLines:\n",
    "    # encode line\n",
    "    encodedSequence = [vocabMap[char] for char in line]\n",
    "    # add it to the list\n",
    "    sequences.append(encodedSequence)\n",
    "    \n",
    "print(sequences[: 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 44 37 52 56 41 54  1 10  1]\n",
      " [44 37 52 56 41 54  1 10  1 23]\n",
      " [37 52 56 41 54  1 10  1 23 37]\n",
      " [52 56 41 54  1 10  1 23 37 52]\n",
      " [56 41 54  1 10  1 23 37 52 52]]\n",
      "[23 37 52 52 61]\n"
     ]
    }
   ],
   "source": [
    "# now we need to prepare the input and target matrices\n",
    "\n",
    "# X = sequences[:,:-1] means we are grabbing all the rows from sequences but dropping the last column\n",
    "# .... the last column will be used as the target\n",
    "\n",
    "# y = sequences[:,-1] means we are grabbing all the rows from sequences but only retaining the last column \n",
    "# .... the last column being our target\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "\n",
    "print(X[0:5])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one last thing...\n",
    "# we need to one-hot-encode each character. \n",
    "# That is, each input vector (of sequenceLength) becomes a vector as long as the vocabulary\n",
    "# with a 1 marked for the specific character. \n",
    "\n",
    "# for this we use the to_categorical() function in the Keras API to one-hot-encode\n",
    "\n",
    "sequences = [to_categorical(x, num_classes=vocabSize) for x in X]\n",
    "\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(y, num_classes=vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentially each input becomes a matrice with the following dimensions:\n",
    "# (number_of_sequences, sequenceLength, vocabSize)\n",
    "\n",
    "# and each output becomes a matrice with the following dimensions:\n",
    "# (number_of_sequences, vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21865, 10, 63)\n",
      "(21865, 63)\n",
      "[[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  1.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  1.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  1.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X[0:2])\n",
    "print(y[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batchSize = 20\n",
    "dropOutRate = 0.3\n",
    "lstmCellsNumber = 25\n",
    "\n",
    "activationFunction = \"softmax\"\n",
    "\n",
    "optimizerFunction = \"adam\"\n",
    "# optimizerFunction = \"rmsprop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 25)                8900      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 63)                1638      \n",
      "=================================================================\n",
      "Total params: 10,538\n",
      "Trainable params: 10,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# time to model...\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(lstmCellsNumber, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(dropOutRate))\n",
    "model.add(Dense(vocabSize, activation=activationFunction))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21865/21865 [==============================] - 17s 781us/step - loss: 3.1706 - acc: 0.1637\n",
      "Epoch 2/100\n",
      "21865/21865 [==============================] - 17s 786us/step - loss: 2.9799 - acc: 0.1838\n",
      "Epoch 3/100\n",
      "21865/21865 [==============================] - 17s 797us/step - loss: 2.7915 - acc: 0.2417\n",
      "Epoch 4/100\n",
      "21865/21865 [==============================] - 17s 794us/step - loss: 2.6300 - acc: 0.2770\n",
      "Epoch 5/100\n",
      "21865/21865 [==============================] - 17s 781us/step - loss: 2.5306 - acc: 0.2899\n",
      "Epoch 6/100\n",
      "21865/21865 [==============================] - 17s 780us/step - loss: 2.4702 - acc: 0.3045\n",
      "Epoch 7/100\n",
      "21865/21865 [==============================] - 17s 783us/step - loss: 2.4190 - acc: 0.3189\n",
      "Epoch 8/100\n",
      "21865/21865 [==============================] - 17s 787us/step - loss: 2.3746 - acc: 0.3300\n",
      "Epoch 9/100\n",
      "21865/21865 [==============================] - 17s 780us/step - loss: 2.3452 - acc: 0.3418\n",
      "Epoch 10/100\n",
      "21865/21865 [==============================] - 18s 813us/step - loss: 2.3140 - acc: 0.3471\n",
      "Epoch 11/100\n",
      "21865/21865 [==============================] - 17s 781us/step - loss: 2.2944 - acc: 0.3508\n",
      "Epoch 12/100\n",
      "21865/21865 [==============================] - 17s 787us/step - loss: 2.2730 - acc: 0.3578\n",
      "Epoch 13/100\n",
      "21865/21865 [==============================] - 17s 797us/step - loss: 2.2513 - acc: 0.3625\n",
      "Epoch 14/100\n",
      "21865/21865 [==============================] - 18s 802us/step - loss: 2.2318 - acc: 0.3671\n",
      "Epoch 15/100\n",
      "21865/21865 [==============================] - 17s 785us/step - loss: 2.2172 - acc: 0.3702\n",
      "Epoch 16/100\n",
      "   32/21865 [..............................] - ETA: 38s - loss: 2.5406 - acc: 0.3125"
     ]
    }
   ],
   "source": [
    "#checkpointer = ModelCheckpoint(filepath=bestSavedModel, verbose=1, save_best_only=True)\n",
    "#model.fit(X, y, epochs=epochs, batch_size=batchSize, callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizerFunction, metrics=[\"accuracy\"])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save(bestSavedModel)\n",
    "\n",
    "# save the vocabulary map. We need it for character generation part later.\n",
    "dump(vocabMap, open(mappingFileName, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of the generated character sequence\n",
    "generatedCharSeqLength = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence of characters with a language model\n",
    "def generateSequence(model, reverseVocab, seedRawText, length):\n",
    "    inputText = seedRawText\n",
    "    \n",
    "    # generate a fixed number of characters\n",
    "    for _ in range(length):\n",
    "        \n",
    "        # the seed text needs to be processed just like the training text was.\n",
    "\n",
    "        # encode the characters as integers based on the dictionary\n",
    "        encodedSeedText = [vocabMap[c] for c in inputText]\n",
    "\n",
    "        # truncate sequences to a fixed length using Keras' pad_sequence()\n",
    "        encodedSeedText = pad_sequences([encodedSeedText], maxlen=sequenceLength, truncating='pre')\n",
    "\n",
    "        # one-hot encode\n",
    "        oneHotEncodedSeedText = to_categorical(encodedSeedText, num_classes=vocabSize)\n",
    "        \n",
    "        # use the model to predict character\n",
    "        predCharInt = model.predict_classes(oneHotEncodedSeedText, verbose=0)\n",
    "        predChar = reverseVocab[predCharInt[0]]\n",
    "\n",
    "        # append to input\n",
    "        inputText += predChar\n",
    "        \n",
    "    return inputText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '1': 10, '2': 11, '3': 12, ':': 13, ';': 14, '?': 15, 'A': 16, 'B': 17, 'C': 18, 'D': 19, 'E': 20, 'F': 21, 'G': 22, 'H': 23, 'I': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'R': 31, 'S': 32, 'T': 33, 'W': 34, 'Y': 35, '_': 36, 'a': 37, 'b': 38, 'c': 39, 'd': 40, 'e': 41, 'f': 42, 'g': 43, 'h': 44, 'i': 45, 'j': 46, 'k': 47, 'l': 48, 'm': 49, 'n': 50, 'o': 51, 'p': 52, 'q': 53, 'r': 54, 's': 55, 't': 56, 'u': 57, 'v': 58, 'w': 59, 'x': 60, 'y': 61, 'z': 62}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: '(', 6: ')', 7: ',', 8: '-', 9: '.', 10: '1', 11: '2', 12: '3', 13: ':', 14: ';', 15: '?', 16: 'A', 17: 'B', 18: 'C', 19: 'D', 20: 'E', 21: 'F', 22: 'G', 23: 'H', 24: 'I', 25: 'K', 26: 'L', 27: 'M', 28: 'N', 29: 'O', 30: 'P', 31: 'R', 32: 'S', 33: 'T', 34: 'W', 35: 'Y', 36: '_', 37: 'a', 38: 'b', 39: 'c', 40: 'd', 41: 'e', 42: 'f', 43: 'g', 44: 'h', 45: 'i', 46: 'j', 47: 'k', 48: 'l', 49: 'm', 50: 'n', 51: 'o', 52: 'p', 53: 'q', 54: 'r', 55: 's', 56: 't', 57: 'u', 58: 'v', 59: 'w', 60: 'x', 61: 'y', 62: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# load the model and the text dictionary\n",
    "model.load_weights(bestSavedModel)\n",
    "\n",
    "# vocabMap is a char: int dictionary\n",
    "vocabMap = load(open(mappingFileName, 'rb'))\n",
    "\n",
    "# reverseVocab is a int: char dictionary used to convert the model prediction (int) to char\n",
    "reverseVocab = dict(enumerate(vocabMap))\n",
    "\n",
    "print(vocabMap)\n",
    "print(reverseVocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the seed text file (input text)\n",
    "seedRawText = readTextFile(seedTextFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generatedText = generateSequence(model, reverseVocab, seedRawText, generatedCharSeqLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that to amend, to set right their relations was impossible,\n",
      "because it was impossible to make her attractive again and able to\n",
      "inspire love, or to make him an old man, not susceptible to love. Except\n",
      "deceit and lying nothing could come of it now; and deceit and lying were\n",
      "opposed to his nature.\n",
      "\" she tiok, or tereselles with he wifl comsed the door, he called the mono insold too himainace of anre. \"Well might be of use to her fair; hus selfiess, and that it was quite senseless in our day in whach he was prateed when him arding in alowar, and to he mabed to him at that instadith on his side. \"Well, what alstay, paisend on ahd was alceady wat excing and tor that havingountrend on his wife's bedroom. And thereope, and his handsome face as untersing on excell newander to goine he tailed the herrelestion with his wife was not sleeping in his wife's bedroom. And thereope, and his handsome face as untersing on excell newander to goine he tailed the herrelestion with his wife was not sleeping in his wife's bedroom. And thereope, and his handsome face as untersing on excell newander to goine he tailed the herrelestion with his wife was not sleeping in his wife's bedroom. And thereope, and his handsome face as untersing on excell newander to goine he tailed the herrelestion with his wife was not sleeping in his wife's bedroom. And thereope, and his handsome face as untersing on excell newander to goine he tailed the herrelestion with his wife was not sleeping in his wife's bedroom. And thereope, and his handsome face as untersing on excell newander to goine he tailed the herrelestion with his wife was not sleeping in his wife's bedroom. And thereope, and his handsome face as untersing on excell newander to goine he tailed the herrelestion with his wife was not sleeping in his wife's bedroom. And thereope, and his handsome face as untersing on excell newander to goine he tailed the herrelestion with his wife was not sleeping in his wife's bedroom. And thereope, and his handsome face as untersing on excell newander to goine he tailed the herrelestion with his wife was not sleeping in his wife's bedroom. And thereope, and his handsome face as untersing on excell newander to goine he tailed the herrelestion with his wife was not sleeping in his wife's bedroom. And there\n"
     ]
    }
   ],
   "source": [
    "print(generatedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
